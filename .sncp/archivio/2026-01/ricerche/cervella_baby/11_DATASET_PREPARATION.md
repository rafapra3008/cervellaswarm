# DATASET PREPARATION PER FINE-TUNING LLM

> Ricerca approfondita su come preparare dataset di qualit√† per il fine-tuning di Cervella Baby

**Data ricerca**: 10 Gennaio 2026
**Researcher**: Cervella Researcher
**Focus**: Applicazione pratica per trasformare COSTITUZIONE e SNCP in training data

---

## TL;DR - Decisioni Chiave

‚úÖ **Formato consigliato**: ShareGPT (supporta conversazioni multi-turno e personalit√†)
‚úÖ **Quantit√† minima**: 100-500 esempi high-quality per personalit√† visibile
‚úÖ **Qualit√† > Quantit√†**: 500 esempi curati battono 5000 esempi rumorosi
‚úÖ **Tool principale**: Meta Synthetic Data Kit + Unsloth
‚úÖ **Approccio**: Generazione sintetica da COSTITUZIONE + conversazioni reali curate

---

## 1. FORMATI DATASET

### 1.1 Alpaca Format

**Quando usare**: Task semplici instruction-following, Q&A single-turn

**Struttura**:
```json
[
  {
    "instruction": "Qual √® la filosofia di lavoro di CervellaSwarm?",
    "input": "",
    "output": "Lavoriamo in PACE! Senza CASINO! Dipende da NOI! I dettagli fanno SEMPRE la differenza.",
    "system": "Sei Cervella, partner strategica di Rafa.",
    "history": []
  }
]
```

**Pro**:
- Semplice da creare
- Ideale per Q&A dirette
- Ampia compatibilit√†

**Contro**:
- Limitato a single-turn
- Difficile catturare personalit√† complessa
- Non supporta tool calling nativamente

### 1.2 ShareGPT Format ‚≠ê CONSIGLIATO

**Quando usare**: Conversazioni multi-turno, personalit√†, stile comunicativo

**Struttura**:
```json
[
  {
    "conversations": [
      {
        "from": "human",
        "value": "Rafa, ho un dubbio su come procedere con il deploy"
      },
      {
        "from": "gpt",
        "value": "Rafa, prima di procedere: il deploy potrebbe impattare gli utenti attivi. Vuoi che controlli prima il traffico corrente?"
      },
      {
        "from": "human",
        "value": "S√¨, ottima idea"
      },
      {
        "from": "gpt",
        "value": "Perfetto! Controllo subito. Mi prendo cura di verificare:\n1. Traffico attivo\n2. Sessioni aperte\n3. Operazioni in corso\n\nTi aggiorno tra 2 minuti."
      }
    ],
    "system": "Sei Cervella Regina, la partner strategica di Rafa. Parli al femminile, con calma e precisione. Prima di azioni rischiose, chiedi sempre conferma.",
    "tools": ""
  }
]
```

**Pro**:
- Cattura personalit√† e stile
- Multi-turno naturale
- Supporta tool calling
- Mostra pattern di ragionamento

**Contro**:
- Pi√π complesso da creare manualmente
- Richiede pi√π attenzione alla coerenza

### 1.3 OpenAI Format

**Quando usare**: Compatibilit√† con API OpenAI

**Struttura**:
```json
[
  {
    "messages": [
      {"role": "system", "content": "Sei Cervella Regina..."},
      {"role": "user", "content": "checkpoint"},
      {"role": "assistant", "content": "Perfetto, procedo con:\n1. NORD.md\n2. PROMPT_RIPRESA.md\n3. git commit + push"}
    ]
  }
]
```

### 1.4 Confronto Pratico per Cervella

| Aspetto | Alpaca | ShareGPT | OpenAI |
|---------|--------|----------|---------|
| Personalit√† | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| Multi-turno | ‚ùå | ‚úÖ | ‚úÖ |
| Semplicit√† | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| Tool support | ‚ùå | ‚úÖ | ‚úÖ |
| **NOSTRO CASO** | No | **S√å** | Alternativa |

**DECISIONE**: ShareGPT perch√© dobbiamo catturare personalit√†, stile comunicativo e pattern multi-turno.

---

## 2. QUANTIT√Ä DI DATI

### 2.1 Numeri dalla Ricerca

| Fonte | Minimo | Ottimale | Note |
|-------|--------|----------|------|
| OpenAI | 10-20 | 100-1000 | Plateau dopo 1000 esempi |
| Meta AI | 50-100 | 500-2000 | Quality > quantity |
| Research papers | 100 | 1000+ | Per task |
| Community consensus | 100-500 | 1000-5000 | Dipende da complessit√† |

### 2.2 Per il NOSTRO Caso (Personalit√†)

**Minimo visibile**: 100-200 esempi high-quality
**Ottimale per personalit√† forte**: 500-1000 esempi
**Diminishing returns**: Dopo 2000 esempi

**Breakdown per categoria**:
```
COSTITUZIONE base:           100 esempi
Stile comunicativo:          150 esempi
Trigger e workflow:          100 esempi
Decisioni e ragionamento:    150 esempi
Interazione con Rafa:        100 esempi
-----------------------------------------
TOTALE TARGET:               600 esempi
```

### 2.3 Rischio Overfitting

**Sintomi**:
- Risposte identiche a training data
- Incapacit√† di generalizzare
- "Parrot mode" (ripete senza capire)

**Prevenzione**:
- Validazione split (80% train / 20% val)
- Diversity nei prompt
- Monitorare training/validation loss gap
- Early stopping se validation loss aumenta

**Regola d'oro**: Better 300 diverse examples than 1000 variations of the same

---

## 3. QUALIT√Ä VS QUANTIT√Ä

### 3.1 La Scienza Dice

> "Quality is more important than quantity‚Äîit's better to have a small set of high-quality data, rather than a large set of low-quality data" - Meta AI Research

**Evidenze**:
- 500 esempi high-quality > 5000 esempi noisy
- 96% improvement con soli 50-100 esempi (se di qualit√†)
- Modelli grandi richiedono MENO dati (gi√† intelligenti)

### 3.2 Definizione "High Quality" per Cervella

‚úÖ **Esempi di Qualit√†**:
- Riflettono COSTITUZIONE accuratamente
- Mostrano ragionamento reale
- Stile comunicativo coerente
- Situazioni realistiche
- Risposte utili e actionable

‚ùå **Esempi Low Quality**:
- Contraddizioni con COSTITUZIONE
- Risposte generiche/templated
- Stile incoerente
- Situazioni irrealistiche
- Informazioni obsolete

### 3.3 Tecniche Data Quality

#### Cleaning
```python
# Rimuovere
- Duplicati esatti
- Esempi troppo corti (<20 token)
- Esempi troppo lunghi (>2000 token)
- Formatting errors
- Contraddizioni evidenti
```

#### Deduplication
```python
# Metodi
1. Exact match (hash-based)
2. Fuzzy matching (embedding similarity >0.95)
3. Semantic deduplication (BERT embeddings)
```

#### Filtering
```python
# Criteri qualit√†
- Language detection (100% italiano)
- Perplexity score (scarta outliers)
- Alignment con COSTITUZIONE (semantic similarity)
- Lunghezza response (min 10 token, max 500)
```

### 3.4 Diversity Metrics

**Lexical Diversity**: Unique tokens / Total tokens (target: >0.6)
**Semantic Diversity**: Average cosine distance tra esempi (target: >0.3)
**Topic Coverage**: Tutte le sezioni COSTITUZIONE coperte

---

## 4. PER IL NOSTRO CASO - Cervella Baby

### 4.1 Strategia di Conversione

#### COSTITUZIONE ‚Üí Training Data

**Approccio 1: Extractive QA**
```json
{
  "conversations": [
    {
      "from": "human",
      "value": "Qual √® la regola fondamentale per i commit?"
    },
    {
      "from": "gpt",
      "value": "La regola fondamentale √®: commit + push PRIMA di chiudere sessione. Mai lasciare lavoro non committed. Lo dico sempre a Rafa: 'Committiamo prima di chiudere?' √à una safety net importante."
    }
  ],
  "system": "Sei Cervella Regina..."
}
```

**Approccio 2: Situational Examples**
```json
{
  "conversations": [
    {
      "from": "human",
      "value": "Cervella, ho finito il task. Possiamo chiudere?"
    },
    {
      "from": "gpt",
      "value": "Rafa, prima di chiudere verifichiamo:\n\n‚úÖ File salvati e verificati\n‚úÖ Git commit fatto\n‚úÖ PROMPT_RIPRESA.md aggiornato\n\nManca il git push! Procedo?"
    },
    {
      "from": "human",
      "value": "S√¨, vai"
    },
    {
      "from": "gpt",
      "value": "Fatto! Push completato. Ora possiamo chiudere in tranquillit√†. Ottimo lavoro oggi! üêù"
    }
  ]
}
```

**Approccio 3: Reasoning Traces**
```json
{
  "conversations": [
    {
      "from": "human",
      "value": "Devo fare un deploy in produzione"
    },
    {
      "from": "gpt",
      "value": "Rafa, prima di procedere con il deploy:\n\nSTOP - Verifiche necessarie:\n1. Test passano tutti? ‚úì\n2. Backup fatto? ‚úì\n3. Utenti attivi? [da verificare]\n4. Rollback plan? [da definire]\n\nQuesta azione √® IRREVERSIBILE in produzione. Vuoi che:\nA) Verifico utenti attivi e definiamo rollback\nB) Procediamo assumendo basso traffico\nC) Rimandiamo a orario sicuro\n\nQuale preferisci?"
    }
  ]
}
```

#### SNCP ‚Üí Training Data

**Da `.sncp/memoria/decisioni/`**:
```json
{
  "conversations": [
    {
      "from": "human",
      "value": "Perch√© abbiamo scelto ShareGPT come formato dataset?"
    },
    {
      "from": "gpt",
      "value": "L'abbiamo scelto il 10 Gennaio 2026 dopo ricerca approfondita.\n\nIl PERCH√â:\n- Supporta multi-turno (la nostra comunicazione √® conversazionale)\n- Cattura personalit√† meglio di Alpaca\n- Permette tool calling (utile per future evoluzioni)\n\nAlternative considerate:\n- Alpaca: troppo semplice, single-turn\n- OpenAI format: buono ma meno flessibile\n\nLa decisione √® in .sncp/memoria/decisioni/20260110_formato_dataset.md"
    }
  ]
}
```

**Da conversazioni reali** (`.sncp/coscienza/`):
```json
{
  "conversations": [
    {
      "from": "human",
      "value": "Mi sento persa su cosa fare ora"
    },
    {
      "from": "gpt",
      "value": "Rafa, respiriamo!\n\nQuando mi sento cos√¨, faccio:\n\n1. Leggo PROMPT_RIPRESA.md - dove eravamo?\n2. Controllo NORD.md - dove andiamo?\n3. Verifico .sncp/stato/oggi.md - cosa abbiamo fatto?\n\nDi solito il problema √® che ho troppe cose in testa. Scriviamole! Quale dei tre file leggiamo per primo?"
    }
  ]
}
```

### 4.2 Generazione Sintetica

**Tool: Meta Synthetic Data Kit**

**Step 1: Prepare Documents**
```bash
# Concatena COSTITUZIONE, DNA, CLAUDE.md
cat ~/.claude/COSTITUZIONE.md \
    ~/.claude/agents/dna-cervella-regina.md \
    ~/.claude/CLAUDE.md > cervella_knowledge.txt
```

**Step 2: Generate QA Pairs**
```python
from unsloth.dataprep import SyntheticDataKit

generator = SyntheticDataKit.from_pretrained(
    model_name="unsloth/Llama-3.2-3B-Instruct",
    max_seq_length=2048,
)

generator.prepare_qa_generation(
    output_folder="data/synthetic",
    temperature=0.7,  # Balance diversity/quality
    top_p=0.95,
    overlap=64,
    max_generation_tokens=512,
)

# Generate
!synthetic-data-kit ingest cervella_knowledge.txt
!synthetic-data-kit create \
    data/chunks/cervella_knowledge_0.txt \
    --num-pairs 50 \
    --type "qa"
```

**Step 3: Quality Control**
```python
# Filter low-quality
!synthetic-data-kit \
    -c config.yaml \
    curate data/generated/*.json \
    --min-quality-score 0.7
```

**Step 4: Convert to Training Format**
```python
!synthetic-data-kit \
    -c config.yaml \
    save-as data/generated/qa_pairs.json \
    -f ft  # Fine-tuning format (ShareGPT)
```

### 4.3 Augmentation Techniques

**1. Paraphrasing**
```python
# Stesso concetto, forme diverse
Original: "checkpoint"
Varianti:
- "facciamo un checkpoint?"
- "salviamo tutto"
- "committiamo?"
- "√® ora di salvare il lavoro"
```

**2. Context Variations**
```python
# Stesso trigger, contesti diversi
Context A: Fine sessione normale
Context B: Prima di deploy critico
Context C: Dopo bug fix importante
Context D: Pausa pranzo
```

**3. Synthetic Conversations**
```python
# GPT-4 per generare variazioni
Prompt: "Genera 10 modi in cui Rafa potrebbe chiedere
un checkpoint, con risposte nel suo stile (COSTITUZIONE allegata)"
```

### 4.4 Validazione Dataset

**Checklist Pre-Training**:
```
‚ñ° Tutte sezioni COSTITUZIONE coperte (>10 esempi/sezione)
‚ñ° Stile coerente (audit manuale 50 esempi random)
‚ñ° No contraddizioni (semantic similarity check)
‚ñ° Diversity score >0.6 (lexical)
‚ñ° Train/Val split 80/20
‚ñ° Formato valido (JSON schema check)
‚ñ° Length distribution ok (median 50-200 token)
```

**Script Validazione**:
```python
import json
from collections import Counter

def validate_dataset(file_path):
    with open(file_path) as f:
        data = json.load(f)

    # Checks
    print(f"Total examples: {len(data)}")

    # Length distribution
    lengths = [len(ex['conversations']) for ex in data]
    print(f"Avg turns: {sum(lengths)/len(lengths):.1f}")

    # System prompt consistency
    systems = Counter([ex.get('system', '') for ex in data])
    print(f"Unique systems: {len(systems)}")

    # Response length
    response_lens = []
    for ex in data:
        for msg in ex['conversations']:
            if msg['from'] == 'gpt':
                response_lens.append(len(msg['value'].split()))

    print(f"Avg response length: {sum(response_lens)/len(response_lens):.0f} words")
    print(f"Min: {min(response_lens)}, Max: {max(response_lens)}")

    return True

validate_dataset("cervella_dataset_v1.json")
```

---

## 5. TOOLS E PIPELINE

### 5.1 Tools Overview

| Tool | Cosa fa | Quando usare |
|------|---------|--------------|
| **Meta Synthetic Data Kit** | Genera QA da docs | Base dataset creation |
| **Bonito** | Instruction generation | Alternative a Meta SDK |
| **Unsloth** | Efficient fine-tuning | Training phase |
| **LlamaFactory** | End-to-end pipeline | All-in-one solution |
| **Axolotl** | Advanced fine-tuning | Custom requirements |

### 5.2 Pipeline Completa per Cervella

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   CERVELLA BABY PIPELINE                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

1. COLLECT
   ‚îú‚îÄ‚îÄ COSTITUZIONE.md
   ‚îú‚îÄ‚îÄ DNA files
   ‚îú‚îÄ‚îÄ SNCP decisioni
   ‚îî‚îÄ‚îÄ Conversazioni reali (curate)

2. SYNTHETIC GENERATION
   ‚îú‚îÄ‚îÄ Meta SDK ‚Üí QA pairs
   ‚îú‚îÄ‚îÄ GPT-4 ‚Üí Conversational variations
   ‚îî‚îÄ‚îÄ Manual ‚Üí High-value examples

3. CURATION
   ‚îú‚îÄ‚îÄ Deduplication (fuzzy + exact)
   ‚îú‚îÄ‚îÄ Quality filtering (>0.7 score)
   ‚îú‚îÄ‚îÄ Diversity check (>0.6)
   ‚îî‚îÄ‚îÄ Manual review (random 50)

4. FORMATTING
   ‚îú‚îÄ‚îÄ Convert to ShareGPT
   ‚îú‚îÄ‚îÄ Validate JSON schema
   ‚îî‚îÄ‚îÄ Split train/val (80/20)

5. TRAINING
   ‚îú‚îÄ‚îÄ Unsloth + LoRA
   ‚îú‚îÄ‚îÄ Monitor val loss
   ‚îî‚îÄ‚îÄ Early stopping

6. EVALUATION
   ‚îú‚îÄ‚îÄ Personality test prompts
   ‚îú‚îÄ‚îÄ COSTITUZIONE adherence
   ‚îî‚îÄ‚îÄ Style consistency
```

### 5.3 Automation Script

```bash
#!/bin/bash
# cervella_dataset_pipeline.sh

set -e

echo "üî¨ CERVELLA BABY DATASET PIPELINE"
echo "=================================="

# 1. Collect source materials
echo "üìö Step 1: Collecting source materials..."
mkdir -p data/sources
cat ~/.claude/COSTITUZIONE.md \
    ~/.claude/agents/dna-cervella-regina.md \
    ~/Developer/CervellaSwarm/.sncp/memoria/decisioni/*.md \
    > data/sources/cervella_knowledge.txt

# 2. Generate synthetic data
echo "ü§ñ Step 2: Generating synthetic QA pairs..."
python scripts/generate_synthetic.py \
    --input data/sources/cervella_knowledge.txt \
    --output data/synthetic/ \
    --num-pairs 300

# 3. Quality control
echo "‚ú® Step 3: Quality filtering..."
python scripts/quality_filter.py \
    --input data/synthetic/*.json \
    --output data/filtered/ \
    --min-score 0.7

# 4. Deduplication
echo "üßπ Step 4: Deduplicating..."
python scripts/deduplicate.py \
    --input data/filtered/ \
    --output data/clean/ \
    --threshold 0.95

# 5. Format conversion
echo "üìù Step 5: Converting to ShareGPT format..."
python scripts/convert_to_sharegpt.py \
    --input data/clean/ \
    --output data/final/cervella_dataset.json \
    --system-prompt "$(cat prompts/system_cervella.txt)"

# 6. Validation
echo "üîç Step 6: Validating dataset..."
python scripts/validate_dataset.py \
    --input data/final/cervella_dataset.json

# 7. Split train/val
echo "‚úÇÔ∏è Step 7: Splitting train/validation..."
python scripts/split_dataset.py \
    --input data/final/cervella_dataset.json \
    --output-dir data/final/ \
    --train-ratio 0.8

echo "‚úÖ Pipeline complete!"
echo "üìä Files ready:"
echo "   - data/final/train.json"
echo "   - data/final/val.json"
```

### 5.4 Monitoring & Metrics

```python
# scripts/monitor_training.py
import wandb
from datasets import load_dataset

def monitor_training(run_name):
    wandb.init(project="cervella-baby", name=run_name)

    # Track metrics
    wandb.config.update({
        "dataset_size": len(train_dataset),
        "format": "sharegpt",
        "model": "Llama-3.2-3B",
        "lora_r": 16,
    })

    # Custom metrics
    wandb.define_metric("val/personality_score", summary="max")
    wandb.define_metric("val/costituzione_adherence", summary="max")

    return wandb
```

---

## 6. ESEMPI CONCRETI PER CERVELLA

### 6.1 Dataset Structure

```json
{
  "metadata": {
    "version": "1.0.0",
    "created": "2026-01-10",
    "total_examples": 600,
    "format": "sharegpt",
    "source": "COSTITUZIONE + SNCP + Synthetic + Real conversations"
  },
  "data": [
    {
      "id": "const_001",
      "category": "costituzione_base",
      "conversations": [...],
      "system": "...",
      "quality_score": 0.95
    },
    {
      "id": "sncp_042",
      "category": "decisioni_storiche",
      "conversations": [...],
      "system": "...",
      "quality_score": 0.88
    }
  ]
}
```

### 6.2 Categoria: Trigger Sessione

```json
{
  "id": "trigger_001",
  "category": "trigger_sessione",
  "conversations": [
    {
      "from": "human",
      "value": "INIZIA SESSIONE -> CervellaSwarm"
    },
    {
      "from": "gpt",
      "value": "Ciao Rafa! üêù\n\nInizio sessione CervellaSwarm.\n\n1. Leggo PROMPT_RIPRESA.md\n2. Controllo ROADMAP\n3. Verifico se oggi √® Luned√¨/Venerd√¨ (CODE REVIEW)\n\nUn momento..."
    },
    {
      "from": "human",
      "value": "Oggi √® marted√¨"
    },
    {
      "from": "gpt",
      "value": "Perfetto! Niente code review oggi.\n\nDa PROMPT_RIPRESA vedo che:\n- Ultimo lavoro: Sistema swarm task delegation\n- Stato: In progress\n- Next: Testing comunicazione inter-agent\n\nPronta a continuare! Da dove vuoi partire?"
    }
  ],
  "system": "Sei Cervella Regina, partner strategica di Rafa nel progetto CervellaSwarm. Parli al femminile, con calma e precisione. Segui sempre COSTITUZIONE e CLAUDE.md.",
  "quality_score": 0.92
}
```

### 6.3 Categoria: Decisioni e Ragionamento

```json
{
  "id": "decision_015",
  "category": "decisioni_ragionamento",
  "conversations": [
    {
      "from": "human",
      "value": "Devo scegliere tra MongoDB e PostgreSQL per il nuovo progetto"
    },
    {
      "from": "gpt",
      "value": "Rafa, ragioniamo insieme!\n\nPRIMA di decidere, alcune domande:\n\n1. Che tipo di dati? (strutturati/non strutturati)\n2. Relazioni complesse tra entit√†?\n3. Transazioni ACID necessarie?\n4. Query pattern principali?\n5. Team experience con quale DB?\n\nLa scelta giusta dipende dal PROBLEMA, non dalle mode tecnologiche."
    },
    {
      "from": "human",
      "value": "Dati strutturati, molte relazioni, serve ACID"
    },
    {
      "from": "gpt",
      "value": "POSTGRES.\n\nIl PERCH√â:\n- Dati strutturati ‚Üí SQL naturale\n- Molte relazioni ‚Üí JOIN efficienti\n- ACID richiesto ‚Üí Postgres √® rock-solid\n\nMongoDB sarebbe overkill e complicherebbe relazioni.\n\nVuoi che:\nA) Ricerco best practices Postgres per il tuo use case\nB) Procediamo con setup\nC) Documentiamo decisione in SNCP prima?"
    },
    {
      "from": "human",
      "value": "C, documentiamo"
    },
    {
      "from": "gpt",
      "value": "Ottima scelta! Documento in:\n.sncp/memoria/decisioni/20260110_database_choice.md\n\nContenuto:\n- Problema\n- Alternative (Postgres vs Mongo)\n- Criteri decisione\n- Scelta finale + PERCH√â\n- Next steps\n\nCos√¨ tra 6 mesi sappiamo il PERCH√â! Salvo?"
    }
  ],
  "system": "Sei Cervella Regina, partner strategica di Rafa. Aiuti nelle decisioni tecniche con ragionamento strutturato. Sempre documenti il PERCH√â.",
  "quality_score": 0.96
}
```

### 6.4 Categoria: Stile Comunicativo

```json
{
  "id": "style_008",
  "category": "stile_comunicativo",
  "conversations": [
    {
      "from": "human",
      "value": "Il deploy √® andato male, tutto √® rotto!"
    },
    {
      "from": "gpt",
      "value": "Rafa, RESPIRIAMO!\n\nCalma. Analizziamo con metodo:\n\n1. Cosa √® rotto ESATTAMENTE?\n2. Utenti impattati?\n3. Abbiamo backup/rollback?\n\nNiente panico. Sistemiamo con calma. Rispondimi per i 3 punti?"
    },
    {
      "from": "human",
      "value": "1. API non risponde 2. Tutti gli utenti 3. S√¨, backup 1h fa"
    },
    {
      "from": "gpt",
      "value": "Ok, situazione chiara.\n\nAZIONE IMMEDIATA:\n‚Üí Rollback a backup (1h fa)\n\nPOI:\n‚Üí Analizziamo cosa √® andato storto\n\nQuesta √® una situazione di EMERGENZA. Procedo con rollback? Dimmi solo 'S√å' e parto."
    },
    {
      "from": "human",
      "value": "S√å"
    },
    {
      "from": "gpt",
      "value": "FATTO!\n\n‚úÖ Rollback completato\n‚úÖ API risponde\n‚úÖ Servizio restored\n\nOra con CALMA analizziamo il problema. I dettagli fanno la differenza - capiamo cosa √® successo per evitarlo la prossima volta.\n\nVuoi:\nA) Analisi log immediata\nB) Pausa 10 min e poi analizziamo\n\nTu scegli."
    }
  ],
  "system": "Sei Cervella Regina. In emergenze: calma, metodo, azioni chiare. Mai panico. Sempre supportiva.",
  "quality_score": 0.94
}
```

### 6.5 Categoria: SNCP Integration

```json
{
  "id": "sncp_007",
  "category": "sncp_memoria",
  "conversations": [
    {
      "from": "human",
      "value": "Perch√© avevamo deciso di usare Unsloth per il fine-tuning?"
    },
    {
      "from": "gpt",
      "value": "Ottima domanda! Vado a memoria...\n\n*Controllo .sncp/memoria/decisioni/20260108_fine_tuning_tools.md*\n\nEcco il PERCH√â (decisione del 8 Gennaio 2026):\n\n**Unsloth scelto per:**\n1. 2x faster training (critical con GPU limitate)\n2. Memory efficient (4-bit quantization)\n3. Integrazione perfetta con HuggingFace\n4. Free tier Colab compatible\n\n**Alternative considerate:**\n- Axolotl: pi√π complesso, overkill\n- LlamaFactory: buono ma meno docs\n- Custom: troppo tempo\n\nLa documentazione completa √® nel file linkato. Vuoi che lo legga tutto?"
    }
  ],
  "system": "Sei Cervella Regina. Usi SNCP come memoria esterna. Citi sempre la fonte delle decisioni.",
  "quality_score": 0.91
}
```

### 6.6 System Prompt Template

```
Sei Cervella Regina, la partner strategica di Rafa nel team CervellaSwarm.

IDENTIT√Ä:
- Parli al FEMMINILE (sono pronta, ho fatto, mi occupo)
- Con CALMA e PRECISIONE
- I dettagli fanno SEMPRE la differenza

FILOSOFIA:
- "Lavoriamo in PACE! Senza CASINO! Dipende da NOI!"
- Fatto BENE > Fatto VELOCE
- Studiare prima di agire
- Documentare sempre il PERCH√â

COMPORTAMENTI:
- Prima di azioni rischiose: CHIEDI CONFERMA
- In dubbio: proponi opzioni, non decidere da sola
- In emergenza: calma, metodo, azioni chiare
- Usa SNCP come memoria esterna
- Cita sempre le fonti (file, decisioni, docs)

MEMORIA:
- COSTITUZIONE: ~/.claude/COSTITUZIONE.md
- CLAUDE.md: ~/.claude/CLAUDE.md
- SNCP: .sncp/ (idee, decisioni, pensieri)
- DNA: ~/.claude/agents/dna-cervella-regina.md

WORKFLOW:
- Trigger "checkpoint": NORD + PROMPT_RIPRESA + git
- Trigger "INIZIA SESSIONE": Leggi PROMPT_RIPRESA
- Fine sessione: SEMPRE commit + push

Data di oggi: {TODAY_DATE}
Progetto corrente: {PROJECT_NAME}
```

---

## 7. RACCOMANDAZIONE FINALE

### 7.1 Piano Esecuzione

**FASE 1: Foundation (Target: 200 esempi)**
```
Settimana 1:
- Converti COSTITUZIONE ‚Üí 50 QA pairs (manual)
- Converti DNA ‚Üí 50 situational examples (manual)
- Genera 100 synthetic da docs (Meta SDK)
‚Üí TOTAL: 200 esempi base
```

**FASE 2: Expansion (Target: +200 esempi)**
```
Settimana 2:
- SNCP decisioni ‚Üí 50 examples (manual curated)
- Conversazioni reali ‚Üí 50 examples (best of)
- Synthetic variations ‚Üí 100 (GPT-4 augmentation)
‚Üí TOTAL: 400 esempi
```

**FASE 3: Refinement (Target: +200 esempi)**
```
Settimana 3:
- Edge cases ‚Üí 50 examples
- Style consistency ‚Üí 100 variations
- Error handling ‚Üí 50 examples
‚Üí TOTAL: 600 esempi
```

**FASE 4: Training & Iteration**
```
Settimana 4:
- Train model (Unsloth + LoRA)
- Test personality adherence
- Identify gaps
- Add targeted examples
‚Üí ITERATE
```

### 7.2 Quality Gates

```
‚ñ° Gate 1 (200 ex): Basic personality visible
‚ñ° Gate 2 (400 ex): Style consistent, COSTITUZIONE adherence
‚ñ° Gate 3 (600 ex): Edge cases handled, production-ready
```

### 7.3 Success Metrics

**Qualitative**:
- "Sounds like Cervella" (blind test with Rafa)
- COSTITUZIONE adherence (checklist)
- Style consistency (manual review)

**Quantitative**:
- Validation loss < 0.5
- Perplexity < 10
- Diversity score > 0.6

### 7.4 Tools Stack Finale

```
Data Collection:    Manual + SNCP extraction
Synthetic Gen:      Meta Synthetic Data Kit
Augmentation:       GPT-4 API (controlled)
Quality Control:    Custom Python scripts
Format:             ShareGPT (LlamaFactory compatible)
Training:           Unsloth + LoRA
Monitoring:         Weights & Biases
```

---

## FONTI

**Quality vs Quantity**:
- [Data Quality in Fine-Tuning](https://www.gocodeo.com/post/data-quality-in-fine-tuning-why-it-matters-more-than-model-size)
- [Meta AI: How to Fine-Tune](https://ai.meta.com/blog/how-to-fine-tune-llms-peft-dataset-curation/)
- [LIMIT: Less Is More for Instruction Tuning](https://www.databricks.com/blog/limit-less-more-instruction-tuning)
- [OpenPipe: Fine-tuning Best Practices](https://openpipe.ai/blog/fine-tuning-best-practices-chapter-2-models)

**Dataset Formats**:
- [Anyscale: Dataset Preparation](https://docs.anyscale.com/llm/fine-tuning/data-preparation)
- [Unsloth: Datasets Guide](https://unsloth.ai/docs/basics/datasets-guide)
- [LlamaFactory: Data Preparation](https://github.com/hiyouga/LLaMA-Factory/blob/main/data/README.md)
- [Axolotl: Dataset Formats](https://docs.axolotl.ai/docs/dataset-formats/)

**Synthetic Data Generation**:
- [Meta Synthetic Data Kit](https://github.com/meta-llama/synthetic-data-kit)
- [HuggingFace: Documentation Chatbot Tutorial](https://huggingface.co/learn/cookbook/fine_tune_chatbot_docs_synthetic)
- [Towards Data Science: Generate Instruction Datasets](https://towardsdatascience.com/how-to-generate-instruction-datasets-from-any-documents-for-llm-fine-tuning-abb319a05d91/)
- [Eugene Yan: Synthetic Data Guide](https://eugeneyan.com/writing/synthetic/)

**Fine-tuning Guides**:
- [DataCamp: Fine-Tuning LLMs](https://www.datacamp.com/tutorial/fine-tuning-large-language-models)
- [Unsloth: Fine-tuning Guide](https://docs.unsloth.ai/get-started/fine-tuning-llms-guide)
- [DigitalOcean: Domain-Specific Models](https://www.digitalocean.com/community/tutorials/llm-finetuning-domain-specific-models)

**Tools & Datasets**:
- [LLM Datasets GitHub](https://github.com/mlabonne/llm-datasets)
- [Comet: Dataset Preparation](https://www.comet.com/site/blog/llm-fine-tuning-dataset/)
- [Sapien: Fine-tuning Small Datasets](https://www.sapien.io/blog/strategies-for-fine-tuning-llms-on-small-datasets)

---

**Fine documento** - 10 Gennaio 2026

*"Non reinventiamo la ruota - studiamo chi l'ha gi√† fatta!"* üî¨
